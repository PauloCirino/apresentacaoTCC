?mlat
?MLAT
require(MLAT)
?MLAT
hypotessesTesting
anovaTest
MLAT::GetDataSetsNames(task = 'Regression')
MLAT::GetPossibleTasks()
MLAT::GetDataSetsNames(task = 'MultClass')
MLAT::GetDataSetsNames(task = 'MultClass')
MLAT::GetAllMultClassAlgo()
MLAT::GetAllMultClassAlgo()[[1]]
sapply(algoList, function(x){x[['algoName']]})
algoList <- MLAT::GetAllMultClassAlgo()
sapply(algoList, function(x){x[['algoName']]})
print( sapply(algoList, function(x){x[['algoName']]}) )
names(algoList[[1]])
algoList[[1]]
algoList[[1]]
algoList[[1]][['algoFun']]
MLAT::GetPossibleTasks()
MyNewAlgoFunc
names(algoList[[1]])[['svm_poli']]
algoList[[1]]
```{r, echo = TRUE}
algoList[[1]][['svm_poli']]
algoList[[1]][['svm_poli']]
algoList
MLAT::GetMetrics(task = 'MultClass')
MLAT::GetMetrics(task = 'MultClass')
algoList[[length(algoList) + 1]] <- newAlgoInStandarts
newAlgoInStandarts
# Chunk 2
MyNewAlgoFunc <- function(X_train, Y_train, X_test, k) {
Y_hat <- numeric()
for (i in 1:nrow(X_test)) {
x_iter <- X_test[i,]
distVet <- apply(X_train, 1, function(x) {
sum(abs(x_iter - x))
})
Y_iter_vet <- Y_train[order(distVet)] [1:k]
Y_iter_aux <- numeric()
for (j in 1:k) {
Y_iter_aux <- append(Y_iter_aux,
rep(Y_iter_vet[j],
k - j + 1))
}
unique_y <- unique(Y_iter_aux)
aux_Table <- tabulate(match(Y_iter_aux,  unique_y))
Y_hat[i] <- unique_y[which.max(aux_Table)]
}
Y_hat
}
# Chunk 3
newAlgoInStandarts <- MLAT::CreateAlgo( algoName = 'KNN Mahalanobis Ponderado',
algoFun = MyNewAlgoFunc,
task = 'MultClass',
paramList = list(k = 2:10) )
# Chunk 4
algoList <- MLAT::GetAllMultClassAlgo()
sapply(algoList, function(x){x[['algoName']]})
names(algoList[[1]])
# Chunk 5
algoList[[1]][['algoFun']]
# Chunk 6
algoList[[1]][['task']]
algoList[[1]][['paramList']]
# Chunk 7
MLAT::GetDataSetsNames(task = 'MultClass')
# Chunk 8
MLAT::GetMetrics(task = 'MultClass')
newAlgoInStandarts
algoList[[length(algoList) + 1]] <- newAlgoInStandarts
MLAT::GetDataSetsNames(task = 'MultClass')[1]
# Chunk 2
MyNewAlgoFunc <- function(X_train, Y_train, X_test, k) {
Y_hat <- numeric()
for (i in 1:nrow(X_test)) {
x_iter <- X_test[i,]
distVet <- apply(X_train, 1, function(x) {
sum(abs(x_iter - x))
})
Y_iter_vet <- Y_train[order(distVet)] [1:k]
Y_iter_aux <- numeric()
for (j in 1:k) {
Y_iter_aux <- append(Y_iter_aux,
rep(Y_iter_vet[j],
k - j + 1))
}
unique_y <- unique(Y_iter_aux)
aux_Table <- tabulate(match(Y_iter_aux,  unique_y))
Y_hat[i] <- unique_y[which.max(aux_Table)]
}
Y_hat
}
# Chunk 3
newAlgoInStandarts <- MLAT::CreateAlgo( algoName = 'KNN Mahalanobis Ponderado',
algoFun = MyNewAlgoFunc,
task = 'MultClass',
paramList = list(k = 2:10) )
# Chunk 4
algoList <- MLAT::GetAllMultClassAlgo()
sapply(algoList, function(x){x[['algoName']]})
names(algoList[[1]])
# Chunk 5
algoList[[1]][['algoFun']]
# Chunk 6
algoList[[1]][['task']]
algoList[[1]][['paramList']]
# Chunk 7
MLAT::GetDataSetsNames(task = 'MultClass')
# Chunk 8
MLAT::GetMetrics(task = 'MultClass')
MLAT::RunTests(cmpTestsFuncsList = algoList,
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
# Chunk 2
MyNewAlgoFunc <- function(X_train, Y_train, X_test, k) {
Y_hat <- numeric()
for (i in 1:nrow(X_test)) {
x_iter <- X_test[i,]
distVet <- apply(X_train, 1, function(x) {
sum(abs(x_iter - x))
})
Y_iter_vet <- Y_train[order(distVet)] [1:k]
Y_iter_aux <- numeric()
for (j in 1:k) {
Y_iter_aux <- append(Y_iter_aux,
rep(Y_iter_vet[j],
k - j + 1))
}
unique_y <- unique(Y_iter_aux)
aux_Table <- tabulate(match(Y_iter_aux,  unique_y))
Y_hat[i] <- unique_y[which.max(aux_Table)]
}
Y_hat
}
# Chunk 3
newAlgoInStandarts <- MLAT::CreateAlgo( algoName = 'KNN Mahalanobis Ponderado',
algoFun = MyNewAlgoFunc,
task = 'MultClass',
paramList = list(k = 2:10) )
# Chunk 4
algoList <- MLAT::GetAllMultClassAlgo()
sapply(algoList, function(x){x[['algoName']]})
names(algoList[[1]])
# Chunk 5
algoList[[1]][['algoFun']]
# Chunk 6
algoList[[1]][['task']]
algoList[[1]][['paramList']]
# Chunk 7
MLAT::GetDataSetsNames(task = 'MultClass')
# Chunk 8
MLAT::GetMetrics(task = 'MultClass')
# Chunk 2
MyNewAlgoFunc <- function(X_train, Y_train, X_test, k) {
Y_hat <- numeric()
for (i in 1:nrow(X_test)) {
x_iter <- X_test[i,]
distVet <- apply(X_train, 1, function(x) {
sum(abs(x_iter - x))
})
Y_iter_vet <- Y_train[order(distVet)] [1:k]
Y_iter_aux <- numeric()
for (j in 1:k) {
Y_iter_aux <- append(Y_iter_aux,
rep(Y_iter_vet[j],
k - j + 1))
}
unique_y <- unique(Y_iter_aux)
aux_Table <- tabulate(match(Y_iter_aux,  unique_y))
Y_hat[i] <- unique_y[which.max(aux_Table)]
}
Y_hat
}
# Chunk 3
newAlgoInStandarts <- MLAT::CreateAlgo( algoName = 'KNN Mahalanobis Ponderado',
algoFun = MyNewAlgoFunc,
task = 'MultClass',
paramList = list(k = 2:10) )
# Chunk 4
algoList <- MLAT::GetAllMultClassAlgo()
sapply(algoList, function(x){x[['algoName']]})
names(algoList[[1]])
# Chunk 5
algoList[[1]][['algoFun']]
# Chunk 6
algoList[[1]][['task']]
algoList[[1]][['paramList']]
# Chunk 7
MLAT::GetDataSetsNames(task = 'MultClass')
# Chunk 8
MLAT::GetMetrics(task = 'MultClass')
MLAT::RunTests(cmpTestsFuncsList = algoList[[1]],
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
MLAT::RunTests(cmpTestsFuncsList = algoList[[1]],
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
MLAT::RunTests(cmpTestsFuncsList = algoList[[1]],
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
MLAT::RunTests(cmpTestsFuncsList = algoList[[1]],
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
algoList[[1]]
MLAT::RunTests(cmpTestsFuncsList = list(algoList[[1]], algoList[[2]])
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
# Chunk 2
MyNewAlgoFunc <- function(X_train, Y_train, X_test, k) {
Y_hat <- numeric()
for (i in 1:nrow(X_test)) {
x_iter <- X_test[i,]
distVet <- apply(X_train, 1, function(x) {
sum(abs(x_iter - x))
})
Y_iter_vet <- Y_train[order(distVet)] [1:k]
Y_iter_aux <- numeric()
for (j in 1:k) {
Y_iter_aux <- append(Y_iter_aux,
rep(Y_iter_vet[j],
k - j + 1))
}
unique_y <- unique(Y_iter_aux)
aux_Table <- tabulate(match(Y_iter_aux,  unique_y))
Y_hat[i] <- unique_y[which.max(aux_Table)]
}
Y_hat
}
# Chunk 3
newAlgoInStandarts <- MLAT::CreateAlgo( algoName = 'KNN Mahalanobis Ponderado',
algoFun = MyNewAlgoFunc,
task = 'MultClass',
paramList = list(k = 2:10) )
# Chunk 4
algoList <- MLAT::GetAllMultClassAlgo()
sapply(algoList, function(x){x[['algoName']]})
names(algoList[[1]])
# Chunk 5
algoList[[1]][['algoFun']]
# Chunk 6
algoList[[1]][['task']]
algoList[[1]][['paramList']]
# Chunk 7
MLAT::GetDataSetsNames(task = 'MultClass')
# Chunk 8
MLAT::GetMetrics(task = 'MultClass')
MLAT::RunTests(cmpTestsFuncsList = list(algoList[[1]], algoList[[2]])
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
MLAT::RunTests(cmpTestsFuncsList = list(algoList[[1]], algoList[[2]]),
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
MLAT::RunTests(cmpTestsFuncsList = list(algoList[[1]], algoList[[2]]),
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
MyNewAlgoFunc <- function(X_train, Y_train, X_test, k) {
Y_hat <- numeric()
for (i in 1:nrow(X_test)) {
x_iter <- X_test[i,]
distVet <- apply(X_train, 1, function(x) {
sum(abs(x_iter - x))
})
Y_iter_vet <- Y_train[order(distVet)] [1:k]
Y_iter_aux <- numeric()
for (j in 1:k) {
Y_iter_aux <- append(Y_iter_aux,
rep(Y_iter_vet[j],
k - j + 1))
}
unique_y <- unique(Y_iter_aux)
aux_Table <- tabulate(match(Y_iter_aux,  unique_y))
Y_hat[i] <- unique_y[which.max(aux_Table)]
}
Y_hat
}
library('MLAT')
library('MLAT')
MyNewAlgoFunc <- function(X_train, Y_train, X_test, k) {
Y_hat <- numeric()
for (i in 1:nrow(X_test)) {
x_iter <- X_test[i,]
distVet <- apply(X_train, 1, function(x) {
sum(abs(x_iter - x))
})
Y_iter_vet <- Y_train[order(distVet)] [1:k]
Y_iter_aux <- numeric()
for (j in 1:k) {
Y_iter_aux <- append(Y_iter_aux,
rep(Y_iter_vet[j],
k - j + 1))
}
unique_y <- unique(Y_iter_aux)
aux_Table <- tabulate(match(Y_iter_aux,  unique_y))
Y_hat[i] <- unique_y[which.max(aux_Table)]
}
Y_hat
}
newAlgoInStandarts <- MLAT::CreateAlgo( algoName = 'KNN Mahalanobis Ponderado',
algoFun = MyNewAlgoFunc,
task = 'MultClass',
paramList = list(k = 2:10) )
algoList <- MLAT::GetAllMultClassAlgo()
MLAT::RunTests(cmpTestsFuncsList = list(algoList[[1]], algoList[[2]]),
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
# Chunk 2
library('MLAT')
# Chunk 3
MyNewAlgoFunc <- function(X_train, Y_train, X_test, k) {
Y_hat <- numeric()
for (i in 1:nrow(X_test)) {
x_iter <- X_test[i,]
distVet <- apply(X_train, 1, function(x) {
sum(abs(x_iter - x))
})
Y_iter_vet <- Y_train[order(distVet)] [1:k]
Y_iter_aux <- numeric()
for (j in 1:k) {
Y_iter_aux <- append(Y_iter_aux,
rep(Y_iter_vet[j],
k - j + 1))
}
unique_y <- unique(Y_iter_aux)
aux_Table <- tabulate(match(Y_iter_aux,  unique_y))
Y_hat[i] <- unique_y[which.max(aux_Table)]
}
Y_hat
}
# Chunk 4
newAlgoInStandarts <- MLAT::CreateAlgo( algoName = 'KNN Mahalanobis Ponderado',
algoFun = MyNewAlgoFunc,
task = 'MultClass',
paramList = list(k = 2:10) )
# Chunk 5
algoList <- MLAT::GetAllMultClassAlgo()
sapply(algoList, function(x){x[['algoName']]})
names(algoList[[1]])
# Chunk 6
algoList[[1]][['algoFun']]
# Chunk 7
algoList[[1]][['task']]
algoList[[1]][['paramList']]
# Chunk 8
MLAT::GetDataSetsNames(task = 'MultClass')
# Chunk 9
MLAT::GetMetrics(task = 'MultClass')
library('MLAT')
library('MLAT')
install.packages("devtools")
library('devtools')
devtools::install_github(repo = 'PauloCirino/MLAT')
# Chunk 2
library('MLAT')
# Chunk 3
MyNewAlgoFunc <- function(X_train, Y_train, X_test, k) {
Y_hat <- numeric()
for (i in 1:nrow(X_test)) {
x_iter <- X_test[i,]
distVet <- apply(X_train, 1, function(x) {
sum(abs(x_iter - x))
})
Y_iter_vet <- Y_train[order(distVet)] [1:k]
Y_iter_aux <- numeric()
for (j in 1:k) {
Y_iter_aux <- append(Y_iter_aux,
rep(Y_iter_vet[j],
k - j + 1))
}
unique_y <- unique(Y_iter_aux)
aux_Table <- tabulate(match(Y_iter_aux,  unique_y))
Y_hat[i] <- unique_y[which.max(aux_Table)]
}
Y_hat
}
# Chunk 4
newAlgoInStandarts <- MLAT::CreateAlgo( algoName = 'KNN Mahalanobis Ponderado',
algoFun = MyNewAlgoFunc,
task = 'MultClass',
paramList = list(k = 2:10) )
# Chunk 5
algoList <- MLAT::GetAllMultClassAlgo()
sapply(algoList, function(x){x[['algoName']]})
names(algoList[[1]])
# Chunk 6
algoList[[1]][['algoFun']]
# Chunk 7
algoList[[1]][['task']]
algoList[[1]][['paramList']]
# Chunk 8
MLAT::GetDataSetsNames(task = 'MultClass')
# Chunk 9
MLAT::GetMetrics(task = 'MultClass')
# Chunk 11
MLAT::RunTests(cmpTestsFuncsList = list(algoList[[1]], algoList[[2]]),
task = 'MultClass',
dataSetNames = MLAT::GetDataSetsNames(task = 'MultClass')[1],
metrics = MLAT::GetMetrics(task = 'MultClass'),
nTestsPerParam = 10,
splitPerc = 0.7,
verbose = TRUE)
library(png)
library(grid)
install.packages('grid', 'png')
install.packages(png')
install.packages('png')
install.packages('png')
knitr::opts_chunk$set(echo = FALSE)
install.packages("devtools")
library('devtools')
devtools::install_github(repo = 'PauloCirino/MLAT')
install.packages("devtools")
knitr::opts_chunk$set(echo = FALSE)
library('devtools')
devtools::install_github(repo = 'PauloCirino/MLAT')
library('MLAT')
?MLAT::hypotessesTesting
load('./data/myData.RData')
resultTable <- myResult
saveRDS(object = resultTable, file = './data/resultTable.rds')
resultTable <- readRDS(file = './data/resultTable.rds')
hypotesesTest <- hypotessesTesting(
resultTable = resultTable,
testingMetric = 'F1 Macro',
method = 'friedman',
reductionMethod = 'mean',
reductionOrder = 'max',
alpha = 0.05)
MLAT::hypotesesTest <- hypotessesTesting(
resultTable = resultTable,
testingMetric = 'F1 Macro',
method = 'friedman',
reductionMethod = 'mean',
reductionOrder = 'max',
alpha = 0.05)
resultTable
hypotesesTest
hypotessesTesting
hypotessesTesting
MLAT::
MLAT::hypotessesTesting
hypotessesTesting(resultTable = myResult,
testingMetric = 'F1 Macro',
method = 'friedman',
reductionMethod = 'mean',
reductionOrder = 'max',
alpha = 0.05)
require(MLAT)
require(MLAT)
hypotessesTesting
require(MLAT)
MLAT::HypotessesTest
knitr::opts_chunk$set(echo = FALSE)
resultTable <- readRDS(file = './data/resultTable.rds')
hypotessesTestResult <- MLAT::HypotessesTest(
resultTable = resultTable,
testingMetric = 'F1 Macro',
method = 'friedman',
reductionMethod = 'mean',
reductionOrder = 'max',
alpha = 0.05)
hypotessesTestResult <- MLAT::HypotessesTest(
resultTable = resultTable,
testingMetric = 'F1 Macro',
method = 'friedman',
reductionMethod = 'mean',
reductionOrder = 'max',
alpha = 0.05)
names(hypotessesTestResult)
